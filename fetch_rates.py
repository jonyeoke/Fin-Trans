import requests
import os
import sys
import pandas as pd
import logging
from datetime import datetime, timedelta
from dotenv import load_dotenv

# utils í´ë”ì˜ handle_sql.pyì—ì„œ í•¨ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
try:
    from utils.handle_sql import execute_query, execute_many
except ImportError:
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from utils.handle_sql import execute_query, execute_many

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# --- [ë¡œê¹… ì„¤ì •] ---
def setup_logging():
    # 1. logs í´ë” ìƒì„±
    log_dir = "logs"
    os.makedirs(log_dir, exist_ok=True)
    
    # 2. ë¡œê·¸ íŒŒì¼ ê²½ë¡œ (execution.log ë¡œ ê³ ì •í•˜ì—¬ ë§¤ë²ˆ ë®ì–´ì“°ê¸°)
    log_file = os.path.join(log_dir, "execution.log")

    # 3. ë¡œê±° ì„¤ì •
    # 'filemode="w"' -> íŒŒì¼ì„ ì—´ ë•Œë§ˆë‹¤ ê¸°ì¡´ ë‚´ìš©ì„ ì§€ìš°ê³  ìƒˆë¡œ ì”€ (ë®ì–´ì“°ê¸°)
    # 'filemode="a"' -> ê¸°ì¡´ ë‚´ìš© ë’¤ì— ê³„ì† ì´ì–´ ë¶™ì´ê¸° (Append)
    logging.basicConfig(
        level=logging.INFO,
        format="[%(asctime)s] %(levelname)s: %(message)s",
        handlers=[
            logging.FileHandler(log_file, mode='w', encoding='utf-8'), # íŒŒì¼ ì €ì¥ (ë®ì–´ì“°ê¸° ëª¨ë“œ)
            logging.StreamHandler(sys.stdout) # í„°ë¯¸ë„ ì¶œë ¥
        ]
    )
    logging.info("ğŸ“ ë¡œê·¸ ì„¤ì • ì™„ë£Œ. ìë™í™” ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

def fetch_koreaexim_rates():
    """í•œêµ­ìˆ˜ì¶œì…ì€í–‰ APIì—ì„œ í™˜ìœ¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    auth_key = os.getenv('EXCHANGE_KEY')
    if not auth_key:
        logging.error("âŒ Error: í™˜ê²½ë³€ìˆ˜ EXCHANGE_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None

    target_date = datetime.now()
    max_retries = 10 
    
    url = "https://www.koreaexim.go.kr/site/program/financial/exchangeJSON"

    for i in range(max_retries):
        search_date_str = target_date.strftime("%Y%m%d")
        logging.info(f"ğŸ”„ ì‹œë„ {i+1}: {search_date_str} ë°ì´í„° ì¡°íšŒ ì¤‘...")

        params = {
            'authkey': auth_key,
            'searchdate': search_date_str,
            'data': 'AP01'
        }

        try:
            response = requests.get(url, params=params, verify=False)
            
            if response.status_code == 200:
                data = response.json()
                if isinstance(data, list) and data:
                    logging.info(f"âœ… ì„±ê³µ! {search_date_str} ê¸°ì¤€ ë°ì´í„°ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
                    return data, search_date_str 
                else:
                    logging.warning(f"âš ï¸ {search_date_str} ë°ì´í„° ì—†ìŒ (íœ´ì¼ ë“±)")
            else:
                logging.error(f"âŒ ìš”ì²­ ì‹¤íŒ¨ (Status: {response.status_code})")

        except Exception as e:
            logging.error(f"âŒ API ìš”ì²­ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")

        target_date -= timedelta(days=1)

    logging.error("âŒ ìµœê·¼ 10ì¼ê°„ì˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return None, None

def save_to_mysql(df, date_str):
    """ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ MySQLì— ì €ì¥í•©ë‹ˆë‹¤."""
    formatted_date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"

    try:
        logging.info(f"ğŸ”Œ MySQL ì €ì¥ ì‹œì‘ (ê¸°ì¤€ì¼: {formatted_date})")
        
        # 1. ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
        delete_sql = "DELETE FROM exchange_rates WHERE reference_date = %s"
        deleted_count = execute_query(delete_sql, (formatted_date,))
        logging.info(f"ğŸ—‘ï¸  ê¸°ì¡´ ë°ì´í„° {deleted_count}ê±´ ì‚­ì œ ì™„ë£Œ.")

        # 2. ìƒˆ ë°ì´í„° ì‚½ì…
        insert_sql = """
        INSERT INTO exchange_rates 
        (reference_date, currency_code, currency_name, deal_bas_r, ttb, tts)
        VALUES (%s, %s, %s, %s, %s, %s)
        """
        
        data_list = []
        for _, row in df.iterrows():
            data_list.append((
                formatted_date,
                row['í†µí™”ì½”ë“œ'],
                row['êµ­ê°€/í†µí™”ëª…'],
                row['ë§¤ë§¤ê¸°ì¤€ìœ¨'],
                row['ì „ì‹ í™˜_ë°›ìœ¼ì‹¤ë•Œ'],
                row['ì „ì‹ í™˜_ë³´ë‚´ì‹¤ë•Œ']
            ))
        
        inserted_count = execute_many(insert_sql, data_list)
        logging.info(f"ğŸ“¥ ìƒˆ ë°ì´í„° {inserted_count}ê±´ DB ì €ì¥ ì™„ë£Œ.")

    except Exception as e:
        logging.error(f"âŒ DB ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def process_and_save(data, date_str):
    """ë°ì´í„° ì „ì²˜ë¦¬(ì½¤ë§ˆ ì œê±° í¬í•¨) ë° ì €ì¥"""
    if not data:
        return

    # 1. DataFrame ìƒì„±
    df = pd.DataFrame(data)

    # 2. ì»¬ëŸ¼ëª… ì†Œë¬¸ìë¡œ í†µì¼
    df.columns = [c.lower() for c in df.columns]

    column_mapping = {
        'cur_unit': 'í†µí™”ì½”ë“œ',
        'cur_nm': 'êµ­ê°€/í†µí™”ëª…',
        'ttb': 'ì „ì‹ í™˜_ë°›ìœ¼ì‹¤ë•Œ',
        'tts': 'ì „ì‹ í™˜_ë³´ë‚´ì‹¤ë•Œ',
        'deal_bas_r': 'ë§¤ë§¤ê¸°ì¤€ìœ¨',
        'bkpr': 'ì¥ë¶€ê°€ê²©',
        'yy_efee_r': 'ë…„í™˜ê°€ë£Œìœ¨',
        'ten_dd_efee_r': '10ì¼í™˜ê°€ë£Œìœ¨',
        'kftc_deal_bas_r': 'ì„œìš¸ì™¸êµ­í™˜ì¤‘ê°œ_ë§¤ë§¤ê¸°ì¤€ìœ¨',
        'kftc_bkpr': 'ì„œìš¸ì™¸êµ­í™˜ì¤‘ê°œ_ì¥ë¶€ê°€ê²©'
    }

    rename_map = {k: v for k, v in column_mapping.items() if k in df.columns}
    df.rename(columns=rename_map, inplace=True)
    
    # 3. ê¸°ì¤€ì¼ì ì¶”ê°€
    df['ê¸°ì¤€ì¼ì'] = date_str
    
    # 4. ìˆ«ì ì»¬ëŸ¼ ë³€í™˜
    target_numeric_cols = [
        'ë§¤ë§¤ê¸°ì¤€ìœ¨', 'ì „ì‹ í™˜_ë°›ìœ¼ì‹¤ë•Œ', 'ì „ì‹ í™˜_ë³´ë‚´ì‹¤ë•Œ', 
        'ì¥ë¶€ê°€ê²©', 'ë…„í™˜ê°€ë£Œìœ¨', '10ì¼í™˜ê°€ë£Œìœ¨', 
        'ì„œìš¸ì™¸êµ­í™˜ì¤‘ê°œ_ë§¤ë§¤ê¸°ì¤€ìœ¨', 'ì„œìš¸ì™¸êµ­í™˜ì¤‘ê°œ_ì¥ë¶€ê°€ê²©'
    ]
    
    for col in target_numeric_cols:
        if col in df.columns:
            df[col] = df[col].astype(str).str.replace(",", "").str.strip()
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

    # 5. ì €ì¥í•  ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬
    final_columns = ['ê¸°ì¤€ì¼ì'] + list(rename_map.values())
    final_columns = [c for c in final_columns if c in df.columns]
    df = df[final_columns]

    # --- CSV ì €ì¥ ---
    save_dir = "data"
    os.makedirs(save_dir, exist_ok=True)
    csv_filename = os.path.join(save_dir, "exchange_rates.csv")
    df.to_csv(csv_filename, index=False, encoding='utf-8-sig')
    logging.info(f"ğŸ’¾ CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {csv_filename}")
    
    # --- MySQL ì €ì¥ ---
    save_to_mysql(df, date_str)

if __name__ == "__main__":
    import urllib3
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

    # ë¡œê¹… ì‹œì‘ ì„¤ì •
    setup_logging()

    logging.info("ğŸš€ í™˜ìœ¨ ì •ë³´ ì—…ë°ì´íŠ¸ ì‹œì‘...")
    rates_data, rates_date = fetch_koreaexim_rates()
    
    if rates_data:
        process_and_save(rates_data, rates_date)
        logging.info("ğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        logging.warning("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ì–´ ì¢…ë£Œí•©ë‹ˆë‹¤.")