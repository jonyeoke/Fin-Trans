import requests
import os
import sys
import pandas as pd
import logging
import re
import io
from datetime import datetime
from dotenv import load_dotenv

current_file_path = os.path.abspath(__file__)
project_root = os.path.dirname(os.path.dirname(current_file_path))

if project_root not in sys.path:
    sys.path.append(project_root)

try:
    from utils.handle_sql import execute_query, execute_many
except ImportError as e:
    logging.error(f"âŒ utils í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œ í™•ì¸ í•„ìš”: {e}")
    sys.exit(1)

load_dotenv()

# --- [ë¡œê¹… ì„¤ì •] ---
def setup_logging():
    log_dir = "logs"
    os.makedirs(log_dir, exist_ok=True)
    log_file = os.path.join(log_dir, "execution.log")

    logging.basicConfig(
        level=logging.INFO,
        format="[%(asctime)s] %(levelname)s: %(message)s",
        handlers=[
            logging.FileHandler(log_file, mode='w', encoding='utf-8-sig'),
            logging.StreamHandler(sys.stdout)
        ]
    )

def fetch_naver_rates():
    """ë„¤ì´ë²„ ê¸ˆìœµ í™˜ìœ¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    url = "https://finance.naver.com/marketindex/exchangeList.naver"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }

    logging.info("ğŸ”„ ë„¤ì´ë²„ ê¸ˆìœµ ë°ì´í„° ìš”ì²­ ì¤‘...")

    try:
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            response.encoding = 'cp949' # ë„¤ì´ë²„ ê¸ˆìœµ ì¸ì½”ë”©
            
            now = datetime.now()
            date_str = now.strftime("%Y%m%d")
            
            save_dir = "data"
            os.makedirs(save_dir, exist_ok=True)
            
            # HTML íŒŒì¼ ì €ì¥
            html_filename = os.path.join(save_dir, "naver_exchange.html")
            try:
                with open(html_filename, "w", encoding="utf-8-sig") as f:
                    f.write(response.text)
            except Exception:
                pass # HTML ì €ì¥ ì‹¤íŒ¨ëŠ” ë¡œê·¸ ìƒëµ

            # ë°ì´í„° íŒŒì‹±
            try:
                html_io = io.StringIO(response.text)
                dfs = pd.read_html(html_io, header=1)
                
                if dfs:
                    df = dfs[0]
                    target_df = df.iloc[:, [0, 1, 4, 5]].copy()
                    target_df.columns = ['raw_name', 'ë§¤ë§¤ê¸°ì¤€ìœ¨', 'ì†¡ê¸ˆ_ë³´ë‚´ì‹¤ë•Œ', 'ì†¡ê¸ˆ_ë°›ìœ¼ì‹¤ë•Œ']
                    
                    logging.info(f"âœ… íŒŒì‹± ì„±ê³µ! ë°ì´í„° {len(target_df)}ê±´ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                    return target_df, date_str
                else:
                    return None, None

            except Exception as parse_error:
                logging.error(f"âš ï¸ íŒŒì‹± ì¤‘ ì—ëŸ¬ ë°œìƒ: {parse_error}")
                return None, None
        else:
            return None, None

    except Exception as e:
        logging.error(f"âŒ í¬ë¡¤ë§ ì—ëŸ¬: {e}")
        return None, None

def process_and_save(df, date_str):
    """ë°ì´í„° ì „ì²˜ë¦¬ ë° ì €ì¥"""
    if df is None or df.empty:
        return

    df = df.copy()

    # 1. êµ­ê°€ëª…ê³¼ í†µí™”ì½”ë“œ ë¶„ë¦¬
    def parse_currency(text):
        text = str(text).strip()
        match = re.search(r'^(.*?)\s+([A-Z]{3})', text)
        if match:
            return match.group(1).strip(), match.group(2).strip()
        return text, 'KRW'

    df[['êµ­ê°€ëª…', 'í†µí™”ëª…']] = df['raw_name'].apply(lambda x: pd.Series(parse_currency(x)))

    # 2. ìˆ«ì ë°ì´í„° ì „ì²˜ë¦¬
    numeric_cols = ['ë§¤ë§¤ê¸°ì¤€ìœ¨', 'ì†¡ê¸ˆ_ë³´ë‚´ì‹¤ë•Œ', 'ì†¡ê¸ˆ_ë°›ìœ¼ì‹¤ë•Œ']
    for col in numeric_cols:
        df[col] = df[col].astype(str).str.replace(",", "").str.strip()
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

    # 3. ê¸°ì¤€ì¼ì ì¶”ê°€
    df['ê¸°ì¤€ì¼ì'] = date_str

    # 4. CSV ì €ì¥ (ìš”ì²­í•˜ì‹  ìˆœì„œ: í†µí™”ëª…, êµ­ê°€ëª…, ë§¤ë§¤ê¸°ì¤€ìœ¨, ë³´ë‚´ì‹¤ë•Œ, ë°›ìœ¼ì‹¤ë•Œ)
    final_columns = ['ê¸°ì¤€ì¼ì', 'í†µí™”ëª…', 'êµ­ê°€ëª…', 'ë§¤ë§¤ê¸°ì¤€ìœ¨', 'ì†¡ê¸ˆ_ë³´ë‚´ì‹¤ë•Œ', 'ì†¡ê¸ˆ_ë°›ìœ¼ì‹¤ë•Œ']
    df = df[final_columns]

    save_dir = "data"
    csv_filename = os.path.join(save_dir, "exchange_rates.csv")
    df.to_csv(csv_filename, index=False, encoding='utf-8-sig')
    logging.info(f"ğŸ’¾ CSV ì €ì¥ ì™„ë£Œ: {csv_filename}")
    
    # --- MySQL ì €ì¥ ---
    save_to_mysql(df, date_str)

def save_to_mysql(df, date_str):
    """MySQL ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ (ìˆ˜ì •ëœ í…Œì´ë¸” êµ¬ì¡° ë°˜ì˜)"""
    formatted_date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"

    try:
        logging.info(f"ğŸ”Œ MySQL ì €ì¥ ì‹œì‘ (ê¸°ì¤€ì¼: {formatted_date})")
        
        # 1. ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
        delete_sql = "DELETE FROM exchange_rates WHERE reference_date = %s or reference_date != %s"
        execute_query(delete_sql, (formatted_date,formatted_date))
        
        # 2. ìƒˆ ë°ì´í„° ì‚½ì… (ì»¬ëŸ¼ëª… ë³€ê²½ ë°˜ì˜: base_rate, send_rate, get_rate)
        insert_sql = """
        INSERT INTO exchange_rates 
        (reference_date, currency_code, currency_name, base_rate, send_rate, get_rate)
        VALUES (%s, %s, %s, %s, %s, %s)
        """
        
        data_list = []
        for _, row in df.iterrows():
            data_list.append((
                formatted_date,
                row['í†µí™”ëª…'],        # currency_code
                row['êµ­ê°€ëª…'],        # currency_name
                row['ë§¤ë§¤ê¸°ì¤€ìœ¨'],     # base_rate
                row['ì†¡ê¸ˆ_ë³´ë‚´ì‹¤ë•Œ'],   # send_rate
                row['ì†¡ê¸ˆ_ë°›ìœ¼ì‹¤ë•Œ']    # get_rate
            ))
        
        inserted_count = execute_many(insert_sql, data_list)
        logging.info(f"ğŸ“¥ DB ì €ì¥ ì™„ë£Œ: {inserted_count}ê±´")

    except Exception as e:
        logging.error(f"âŒ DB ì €ì¥ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    setup_logging()
    
    import urllib3
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

    logging.info("ğŸš€ í™˜ìœ¨ ì •ë³´ ì—…ë°ì´íŠ¸ ì‹œì‘...")
    
    rates_data, rates_date = fetch_naver_rates()
    
    if rates_data is not None:
        process_and_save(rates_data, rates_date)
        logging.info("ğŸ‰ ì‘ì—… ì™„ë£Œ")
    else:
        logging.warning("âš ï¸ ë°ì´í„° ì—†ìŒ")